# Functions used for analysis of ML segmentation algorithm

import sv
from Code import vtk_functions as vf
import numpy as np
import vtk
from vtk.util.numpy_support import vtk_to_numpy as v2n

def extract_plane(SEG_FN):
    """
    Function to extract plane from .vtp segmentation
    Input filename, location
    Output normal, point, tangent(vector in plane)
    """

    kernel = sv.modeling.Kernel.POLYDATA
    modeler = sv.modeling.Modeler(kernel)

    model = modeler.read(SEG_FN)

    model_polydata = model.get_polydata()
    print("Reading Model: num nodes: {0:d}".format(model_polydata.GetNumberOfPoints()))

    np_pts = v2n(model_polydata.GetPoints().GetData())
    num_pts = len(np_pts)

    ids = [0, num_pts//4, num_pts//2, num_pts*3//4]

    #print("Reading vector 1")
    vec_1 = np_pts[ids[2]] - np_pts[ids[0]]
    vec_1 = vec_1/np.linalg.norm(vec_1)

    #print("Reading vector 2")
    vec_2 = (np_pts[ids[3]] - np_pts[ids[1]])
    vec_2 = vec_2/np.linalg.norm(vec_2)

    #print("Calculating cross product")
    vec_3 = np.cross(vec_1, vec_2)
    vec_3 = vec_3/np.linalg.norm(vec_3)

    return np.ndarray.tolist(vec_3), np.ndarray.tolist(np_pts[0]), np.ndarray.tolist(vec_1)

def average_vtp(SEG_FN):
    """
    Function to calculate average point of .vtp file
    Input: .vtp files
    Output: 3D coords of average point, numpy array
    """
    kernel = sv.modeling.Kernel.POLYDATA
    modeler = sv.modeling.Modeler(kernel)

    model = modeler.read(SEG_FN)

    model_polydata = model.get_polydata()

    np_pts = v2n(model_polydata.GetPoints().GetData())

    np_ave = np.average(np_pts,0)

    r_sum = 0
    for i in np_pts:
        r_sum = r_sum + np.linalg.norm(i - np_ave)
    ave_rad = r_sum/len(np_pts)

    return np_ave, ave_rad

def scale_pth(file_directory, path_name, scale):
    """
    Scales a .pth file
    Inputs: (a) file directory string
            (b) pathname string(excluding.pth)
            (c) scale parameter (to be multiplied to points)
                e.g. want scaled by 0.1, then scale is 0.1
    Output: scaled .pth file
    """

    ## Get data of .pth

    paths = sv.pathplanning.Series( str(file_directory + (path_name + ".pth")))

    aorta_path = paths.get_path(0)
    control_points = aorta_path.get_control_points()
    print('Original control points:')
    print(control_points)

    ## Create Series object and Path object
    path_series = sv.pathplanning.Series()
    new_path = sv.pathplanning.Path()

        ## Add control points to path
    print('Calculating new points')
    index = 0
    for pt in control_points:

        pt_a = np.array(pt)*scale
        pt_a = pt_a.tolist()
        aorta_path.replace_control_point(index, pt_a)
        index += 1

        ## Add path to series.
    path_series.set_path(path=new_path, time=0)
    path_series.set_path_id(1)

    paths.set_path(path=aorta_path, time=0)
    paths.set_path_id(1)

    curve_points = aorta_path.get_curve_points()
    print('New control points:')
    print(curve_points)

    ## Write out path series to files

    paths.write(str(file_directory + (path_name + ".pth")))


def calc_seg_distance(ml_segmentation, true_segmentation):
    """
    Function to calculate the distance between segmentation prediction
    and true segmentation point_string
    Way to measure difference, in order to compare different predictions
    Inputs: (a) segmentation prediction (points in vtp.file) as file_name
            (b) segmentation truth (30 point prediction) as python list
    Output: Average distance between prediction points and closest true point
    """

    ## Read in geometry .vtp file

    true_seg = vf.read_geo(true_segmentation).GetOutput()
    n_points_true = true_seg.GetNumberOfPoints()
    n_points_ml = len(ml_segmentation)

    ## Create numpy array of locations

    true_loc = v2n(true_seg.GetPoints().GetData())

    ## Create vtk locator object

    dataset = vtk.vtkPolyData()
    dataset.SetPoints(true_seg.GetPoints())
    locator = vtk.vtkPointLocator()
    locator.Initialize()
    locator.SetDataSet(dataset)
    locator.BuildLocator()

    true_seg.locator = locator

    ## Find closest .vtp point to each ml_segmentation points

    p_closest_ids = []
    for i in ml_segmentation:
        p_closest_ids += [true_seg.locator.FindClosestPoint(i)]

    ## Calculate distance between the points

    a = ml_segmentation
    b = true_loc[p_closest_ids]
    dist = np.ones((n_points_ml), dtype = float)

    for i in range(n_points_ml):
        dist[i] = np.linalg.norm(a[i]-b[i])

    return np.average(dist)


def points2polydata(xyz):
    import vtk
    points = vtk.vtkPoints()
    # Create the topology of the point (a vertex)
    vertices = vtk.vtkCellArray()
    # Add points
    for i in range(0, len(xyz)):
        try:
            p = xyz.loc[i].values.tolist()
        except:
            p = xyz[i]
        if len(p) == 2:
            p.append(0)
        point_id = points.InsertNextPoint(p)
        vertices.InsertNextCell(1)
        vertices.InsertCellPoint(point_id)
    # Create a poly data object
    polydata = vtk.vtkPolyData()
    # Set the points and vertices we created as the geometry and topology of the polydata
    polydata.SetPoints(points)
    polydata.SetVerts(vertices)
    polydata.Modified()

    return polydata

def rotate_to_plane(normal, vector):

    z_vec = np.array([0,0,1])
    v = np.cross(normal,z_vec)

    s = np.linalg.norm(v)
    c = np.dot(z_vec, normal)
    v_x = np.zeros((3,3))
    rot = np.zeros((3,3))
    v_x[0][0] = 0
    v_x[0][1] = -v[2]
    v_x[0][2] = v[1]
    v_x[1][0] = v[2]
    v_x[1][1] = 0
    v_x[1][2] = -v[0]
    v_x[2][0] = -v[1]
    v_x[2][1] = v[0]
    v_x[2][2] = 0

    v_dot = v_x*v_x
    for i in range(3) :
        for j in range(3) :
            rot[i][j] = v_x[i][j] + v_dot[i][j] * (1.0 - c) / s / s
            if i==j:
                rot[i][j] = rot[i][j] + 1.0

    return rot.dot(vector)
